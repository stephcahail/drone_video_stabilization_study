{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_laplace\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video(video):\n",
    "    video = cv2.VideoCapture(video)\n",
    "    frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    video_fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "    frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Exit if video not opened.\n",
    "    if not video.isOpened():\n",
    "        print(\"Could not open video\")\n",
    "        sys.exit()\n",
    "\n",
    "    return (video, frame_width, frame_height, video_fps, frame_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(curve, radius):\n",
    "    window_size = 2 * radius + 1\n",
    "    # Define the filter\n",
    "    f = np.ones(window_size)/window_size\n",
    "    \n",
    "    # Add padding to the boundaries\n",
    "    curve_pad = np.lib.pad(curve, (radius, radius), 'edge')\n",
    "    \n",
    "    # Apply convolution\n",
    "    curve_smoothed = np.convolve(curve_pad, f, mode='same')\n",
    "    \n",
    "    # Remove padding\n",
    "    curve_smoothed = curve_smoothed[radius:-radius]\n",
    "    \n",
    "    # return smoothed curve\n",
    "    return curve_smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(trajectory):\n",
    "    smoothed_trajectory = np.copy(trajectory)\n",
    "    \n",
    "    # Filter the x, y and angle curves\n",
    "    for i in range(3):\n",
    "        smoothed_trajectory[:,i] = moving_average(trajectory[:,i], radius=10)\n",
    "\n",
    "    return smoothed_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplacian_of_gaussian(trajectory):\n",
    "    smoothed_trajectory = np.copy(trajectory)\n",
    "    \n",
    "    # Filter the x, y and angle curves by first using Gaussian blur to smooth the frame\n",
    "    # and then using a Laplacian transform to apply convolution\n",
    "    for i in range(3):\n",
    "        smoothed_trajectory[:,i] = gaussian_laplace(trajectory[:,i], sigma=10)\n",
    "\n",
    "    return smoothed_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixBorder(frame):\n",
    "    s = frame.shape\n",
    "    \n",
    "    # Scale the image 10% without moving the center\n",
    "    T = cv2.getRotationMatrix2D((s[1]/2, s[0]/2), 0, 1.1)\n",
    "    frame = cv2.warpAffine(frame, T, (s[1], s[0]))\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute peak-signal-to-noise ratio between frames\n",
    "def calculate_psnr(video, frame_count):\n",
    "    psnr = np.zeros(frame_count-1, np.float32)\n",
    "    \n",
    "    # Read first frame\n",
    "    _, prev_frame = video.read()\n",
    "    \n",
    "    for i in range(frame_count-2):\n",
    "        re, frame = video.read()\n",
    "        if re == False:\n",
    "            break\n",
    "        \n",
    "        mse = np.mean((np.array(prev_frame, dtype=np.float32) - np.array(frame, dtype=np.float32)) ** 2)\n",
    "        \n",
    "        if mse == 0:\n",
    "            psnr[i] = 100\n",
    "        else:\n",
    "            psnr[i] = 20 * np.log10(255 / (np.sqrt(mse)))\n",
    "\n",
    "        # Move to next frame\n",
    "        prev_frame = frame\n",
    "    \n",
    "    return psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_motion_estimation(video, frame_count, frame_width, frame_height):\n",
    "    transforms = np.zeros((frame_count-1, 3), np.float32)\n",
    "    \n",
    "    # Read first frame\n",
    "    _, prev_frame = video.read()\n",
    "\n",
    "    # Convert frame to grayscale\n",
    "    prev_frame = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    for i in range(frame_count-2):\n",
    "        re, frame = video.read()\n",
    "        if re == False:\n",
    "            break\n",
    "\n",
    "        # convert current frame to grayscale\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect feature points in previous frame\n",
    "        prev_pts = cv2.goodFeaturesToTrack(prev_frame,\n",
    "                                           maxCorners=200,\n",
    "                                           qualityLevel=0.01,\n",
    "                                           minDistance=30,\n",
    "                                           blockSize=3)\n",
    "\n",
    "        # Calculate optical flow (i.e. track feature points)\n",
    "        curr_pts, status, err = cv2.calcOpticalFlowPyrLK(prev_frame, frame, prev_pts, None)\n",
    "\n",
    "        # Sanity check\n",
    "        assert prev_pts.shape == curr_pts.shape\n",
    "\n",
    "        # Filter only valid points\n",
    "        idx = np.where(status==1)[0]\n",
    "        prev_pts = prev_pts[idx]\n",
    "        curr_pts = curr_pts[idx]\n",
    "\n",
    "        # Find transformation matrix\n",
    "        m = cv2.estimateAffinePartial2D(prev_pts, curr_pts)\n",
    "        \n",
    "        # Extract translation\n",
    "        dx = m[0][0,2]\n",
    "        dy = m[0][1,2]\n",
    "\n",
    "        # Extract rotation angle\n",
    "        da = np.arctan2(m[0][1,0], m[0][0,0])\n",
    "\n",
    "        # Store transformation\n",
    "        transforms[i] = [dx,dy,da]\n",
    "\n",
    "        # Move to next frame\n",
    "        prev_frame = frame\n",
    "    \n",
    "    return transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_smooth_motion(transforms, gaussian=False):\n",
    "    # Compute trajectory using cumulative sum of transformations\n",
    "    trajectory = np.cumsum(transforms, axis=0)\n",
    "    \n",
    "    # Calculate smoothed directory\n",
    "    if gaussian is True:\n",
    "        smoothed_trajectory = laplacian_of_gaussian(trajectory)\n",
    "    else:\n",
    "        smoothed_trajectory = smooth(trajectory)\n",
    "\n",
    "    # Calculate difference in smoothed_trajectory and trajectory\n",
    "    difference = smoothed_trajectory - trajectory\n",
    "\n",
    "    # Calculate newer transformation array\n",
    "    transforms_smooth = transforms + difference\n",
    "    \n",
    "    return transforms_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_new_transforms(video, frame_count, frame_width, frame_height, out, new_transforms, gaussian=False):\n",
    "    # Reset stream to first frame\n",
    "    video.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "    for i in range(frame_count-2):\n",
    "        ret, frame = video.read()\n",
    "\n",
    "        if ret == False:\n",
    "            break\n",
    "            \n",
    "        if gaussian is False:\n",
    "            # Extract transformations from the new transformation array\n",
    "            dx = new_transforms[i,0]\n",
    "            dy = new_transforms[i,1]\n",
    "            da = new_transforms[i,2]\n",
    "\n",
    "            # Reconstruct transformation matrix accordingly to new values\n",
    "            m = np.zeros((2,3), np.float32)\n",
    "            m[0,0] = np.cos(da)\n",
    "            m[0,1] = -np.sin(da)\n",
    "            m[1,0] = np.sin(da)\n",
    "            m[1,1] = np.cos(da)\n",
    "            m[0,2] = dx\n",
    "            m[1,2] = dy\n",
    "\n",
    "            # Apply affine wrapping to the given frame\n",
    "            frame = cv2.warpAffine(frame, m, (frame_width,frame_height))\n",
    "        \n",
    "        # Fix border artifacts\n",
    "        frame_stabilized = fixBorder(frame)\n",
    "        \n",
    "        # Write new video to output\n",
    "        out.write(frame_stabilized)\n",
    "\n",
    "        # Write the frame to the file\n",
    "        frame_out = cv2.hconcat([frame, frame_stabilized])\n",
    "\n",
    "        # If the image is too big, resize it.\n",
    "        if(frame_out.shape[1] > 1920):\n",
    "            frame_out = cv2.resize(frame_out, (int(frame_out.shape[1]/3), int(frame_out.shape[0]/3)));\n",
    "            \n",
    "        cv2.imshow(\"Before and After\", frame_out)\n",
    "        cv2.waitKey(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect input video object and characteristics\n",
    "video, frame_width, frame_height, video_fps, frame_count = read_video(\"zilker_park.mp4\") # provided in GitHub\n",
    "#video, frame_width, frame_height, video_fps, frame_count = read_video(\"Videos/Clip_12.mov\") # from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average peak-signal-to-noise ratio for original video frames is: 32.81125259399414\n"
     ]
    }
   ],
   "source": [
    "# get peak-signal-to-noise ratio for original frames\n",
    "original_psnr = calculate_psnr(video, frame_count)\n",
    "original_psnr_avg = np.average(original_psnr)\n",
    "print(\"The average peak-signal-to-noise ratio for original video frames is: {}\".format(original_psnr_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset stream to first frame\n",
    "video.set(cv2.CAP_PROP_POS_FRAMES, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute optical flow for video\n",
    "transforms = compute_motion_estimation(video, frame_count, frame_width, frame_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate new transforms with moving window average filter\n",
    "new_transforms = compute_smooth_motion(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up output video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "out = cv2.VideoWriter('video_out_no_gauss.avi', fourcc, video_fps, (frame_width, frame_height))\n",
    "\n",
    "# apply new transforms to video file\n",
    "apply_new_transforms(video, frame_count, frame_width, frame_height, out, new_transforms, gaussian=False)\n",
    "\n",
    "video.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average peak-signal-to-noise ratio for transformed video frames is: 34.94142150878906\n"
     ]
    }
   ],
   "source": [
    "# get peak-signal-to-noise ratio for new frames\n",
    "output_vid, frame_width, frame_height, video_fps, frame_count = read_video(\"video_out_no_gauss.avi\")\n",
    "\n",
    "new_psnr = calculate_psnr(output_vid, frame_count)\n",
    "new_psnr_avg = np.average(new_psnr)\n",
    "print(\"The average peak-signal-to-noise ratio for transformed video frames is: {}\".format(new_psnr_avg))\n",
    "\n",
    "output_vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate new transforms with laplacian of gaussian filter\n",
    "new_transforms = compute_smooth_motion(transforms, gaussian=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up output video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "out = cv2.VideoWriter('video_out_gauss.avi', fourcc, video_fps, (frame_width, frame_height))\n",
    "\n",
    "# apply new transforms to video file\n",
    "apply_new_transforms(video, frame_count, frame_width, frame_height, out, new_transforms, gaussian=True)\n",
    "\n",
    "video.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average peak-signal-to-noise ratio for transformed video frames is: 33.38200759887695\n"
     ]
    }
   ],
   "source": [
    "# get peak-signal-to-noise ratio for new frames\n",
    "output_vid, frame_width, frame_height, video_fps, frame_count = read_video(\"video_out_gauss.avi\")\n",
    "\n",
    "new_psnr = calculate_psnr(output_vid, frame_count)\n",
    "new_psnr_avg = np.average(new_psnr)\n",
    "print(\"The average peak-signal-to-noise ratio for transformed video frames is: {}\".format(new_psnr_avg))\n",
    "\n",
    "output_vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
